{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--proxy-server=%s' % '102.140.96.180:8080')\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://twitter.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = driver.find_elements_by_xpath('//div[@data-testid=\"tweet\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = anchors[1]\n",
    "anchor.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_name\n",
    "anchor.find_element_by_xpath('.//span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweeter id\n",
    "anchor.find_element_by_xpath('.//span[contains(text() , \"@\")]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = anchor.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "print(date1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor.find_element_by_xpath('.//div[@data-testid=\"like\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text.strip('Replying to').strip('\\n').replace('\\n' , ' ')\n",
    "responding = anchor.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "#tweet = comment + responding\n",
    "print(comment)\n",
    "print('___________')\n",
    "print(responding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Replying' in anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text:\n",
    "    tweet = anchor.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    reply_to =anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text.strip('Replying to').strip('\\n').replace('\\n' , ' ')\n",
    "elif 'Replying' not in anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text:\n",
    "    tweet = anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "    reply_to = anchor.find_element_by_xpath('.//div[2]/div[2]/div[2]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor.find_elements_by_xpath('.//a')[2].get_property('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_data(anchor):\n",
    "    'extract tweet data'\n",
    "    try:\n",
    "        name = anchor.find_element_by_xpath('.//span').text\n",
    "        tweet_id = anchor.find_element_by_xpath('.//span[contains(text() , \"@\")]').text\n",
    "    \n",
    "        post_date = anchor.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    like = anchor.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    if 'Replying' in anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text:\n",
    "        tweeting = anchor.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "        reply_to =anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text.strip('Replying to').strip('\\n').replace('\\n' , ' ')\n",
    "    elif 'Replying' not in anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text:\n",
    "        tweeting = anchor.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "        reply_to = anchor.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    \n",
    "    retweet = anchor.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    \n",
    "    url = anchor.find_elements_by_xpath('.//a')[2].get_property('href')\n",
    "    \n",
    "    tweet = (url , tweet_id , tweeting , like , retweet , reply_to , post_date)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for anchor in anchors:\n",
    "    data = get_tweet_data(anchor)\n",
    "    if data:\n",
    "        tweet_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tweets on page\n",
    "last_position = driver.execute_script('return window.pageYOffset;')\n",
    "scrolling = True\n",
    "\n",
    "while scrolling:\n",
    "    anchors = driver.find_elements_by_xpath('//div[@data-testid=\"tweet\"]')\n",
    "    time.sleep(2)\n",
    "    for anchor in anchors[-20:]:\n",
    "        tweet = get_tweet_data(anchor)\n",
    "        if tweet:\n",
    "            tweet_id = ''.join(tweet)\n",
    "            if tweet_id not in tweet_ids:\n",
    "                tweet_ids.add(tweet_id)\n",
    "                data.append(tweet)\n",
    "                if len(data) % 100 == 0:\n",
    "                    print(len(data))\n",
    "    \n",
    "    scroll_attempt = 0\n",
    "    while True:\n",
    "        # check scroll position\n",
    "        driver.execute_script('window.scrollTo(0 , document.body.scrollHeight);')\n",
    "        time.sleep(5)\n",
    "        curr_position = driver.execute_script('return window.pageYOffset;')\n",
    "        if last_position == curr_position:\n",
    "            scroll_attempt += 1\n",
    "            \n",
    "            # end of scroll region\n",
    "            if scroll_attempt >= 10:\n",
    "                scrolling = False\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(5)\n",
    "        \n",
    "        else:\n",
    "            last_position = curr_position\n",
    "            break\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('covid_tweets.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    header = ['UserName', 'Handle', 'Post_Date', 'Text', 'URL']\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smasco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (url , tweet_id , responding , like , retweet , comment)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data , columns =['URL', 'USER', 'TWEET', 'LIKE', 'RETWEET' , 'TO USER' , 'TWEET_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('MaharaHR.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TWEET_DATE = pd.to_datetime(df.TWEET_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TWEET_DATE.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['TWEET_DATE']= df1['TWEET_DATE'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sort_values('TWEET_DATE', ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'@e_Balady' in datas[-1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for d in datas:\n",
    "    if '@e_Balady' in d[2]:\n",
    "        d[-2] = '@e_Balady'\n",
    "        d[2] = d[2].strip('@e_Balady')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data , open('Balady_CS.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
